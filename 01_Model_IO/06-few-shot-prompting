import os
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

from langchain.prompts import (
    FewShotChatMessagePromptTemplate,
    ChatPromptTemplate,
)

from langchain.chat_models import ChatOpenAI


def main():
    examples = [
        {"input": "2+2", "output": "4"},
        {"input": "2+3", "output": "5"},
    ]
    # This is a prompt template used to format each individual example.
    example_prompt = ChatPromptTemplate.from_messages(
        [
            ("human", "{input}"),
            ("ai", "{output}"),
        ]
    )
    # Pass these both to the template, and it will format it for us.
    few_shot_prompt = FewShotChatMessagePromptTemplate(
        example_prompt=example_prompt,
        examples=examples,
    )
    # Now, we pass it to a regular chat prompt template along with the system template and the human template for whatever we want.
    final_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "You are a wondrous wizard of math."),
            few_shot_prompt,
            ("human", "{input}"),
        ]
    ).format_prompt(input="2+4")

    chat = ChatOpenAI(openai_api_key=api_key)
    result = chat(final_prompt.to_messages())
    print(result.content)


if __name__ == "__main__":
    main()
