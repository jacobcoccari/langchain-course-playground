import os
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.prompts import (
    HumanMessagePromptTemplate,
    ChatPromptTemplate,
)

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")


def call_chat(formatted_prompt):
    chat = ChatOpenAI(openai_api_key=api_key)
    return chat([formatted_prompt.to_messages()])


def main():
    template_string = """Respond to the following customer review in the style of a {style}. 
    
    text: ```{text}```

    """
    prompt_template = ChatPromptTemplate.from_template(template_string)
    # print(prompt_template)
    # We can see that creating a template from a chatprompttemplate automatically makes it a human message.
    # print(prompt_template.messages)
    chat_prompt = ChatPromptTemplate.from_messages([human_message_template])
    request = chat_prompt.format_prompt(comedian="Jerry Seinfeld")

    # print(request)

    # response = call_chat(request)
    # print(type(response))
    # print(response.content)


if __name__ == "__main__":
    main()
