from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv
import os
load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")

def main():
    model = ChatOpenAI(openai_api_key=openai_api_key)
    prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")
    chain = prompt | model
    # Invoke is the way to call the chain on a single input.
    result = chain.invoke({"topic": "bears"})
    print(result)
    # returns an AI message.
    print(type(result))
    print("------")
    # Batch just returns a list of AI messages as opposed to a single one.
    batch_result = chain.batch([{"topic": "bears"}, {"topic": "cats"}])
    print(batch_result)
    

if __name__ == "__main__":
    main()