from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv
import os
load_dotenv()
from langchain.pydantic_v1 import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser

openai_api_key = os.getenv("OPENAI_API_KEY")

class Name(BaseModel):
    first_name: str = Field(..., description="The first name of the person.")
    last_name: str = Field(..., description="The last name of the person.")

def main():
    model = ChatOpenAI(openai_api_key=openai_api_key).bind(functions = Name)
    parser = PydanticOutputParser(pydantic_object=Name)
    template = f"who pioneered the theory of relativity? " + parser.get_format_instructions()
    print(template )
    prompt_template = ChatPromptTemplate.from_template(template)
    print(prompt_template)
    # chain = prompt_template | model
    # result = chain.invoke({"topic": "bears"})
    # # As we can see, the result stops before the punchline because of the stop sequence.
    # print(result.content)


if __name__ == "__main__":
    main()