from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv
import os
load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")

def main():
    model = ChatOpenAI(openai_api_key=openai_api_key).bind(stop=["\n"]  )
    prompt_template = ChatPromptTemplate.from_template("tell me a joke about {topic}")
    chain = prompt_template | model
    result = chain.invoke({"topic": "bears"})
    # As we can see, the result stops before the punchline because of the stop sequence.
    print(result.content)


if __name__ == "__main__":
    main()